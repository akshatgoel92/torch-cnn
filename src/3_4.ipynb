{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " 3.4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VwMGlUSAHYmq",
        "outputId": "b5d00c57-0056-4fb6-c4df-d0f871b11cce"
      },
      "source": [
        "import os\n",
        "\n",
        "stream = os.popen('curl -fsS http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz -o /tmp/train-images-idx3-ubyte.gz')\n",
        "output = stream.read()\n",
        "output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9iEp8_MsV_0N",
        "outputId": "d945f17d-63f4-4401-e4d1-3bd36907cd77"
      },
      "source": [
        "stream = os.popen('curl -fsS http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz -o /tmp/train-labels-idx1-ubyte.gz')\n",
        "output = stream.read()\n",
        "output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g9WAiCXjWMQc",
        "outputId": "ae6d9480-8f3f-449e-9b4b-70935e39adf6"
      },
      "source": [
        "stream = os.popen('curl -fsS http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz -o /tmp/t10k-images-idx3-ubyte.gz')\n",
        "output = stream.read()\n",
        "output"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mqfwj140WZP7",
        "outputId": "6eebf2ad-b9ea-468a-a2d8-1bba0e69f75d"
      },
      "source": [
        "stream = os.popen('curl -fsS http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz -o /tmp/t10k-labels-idx1-ubyte.gz')\n",
        "output = stream.read()\n",
        "output"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBfLek0xWwZo"
      },
      "source": [
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq4tq6X7XGO4"
      },
      "source": [
        "def load_mnist(path, kind='train'):\n",
        "\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '/tmp/%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '/tmp/%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsUMY8Tdd2H8"
      },
      "source": [
        "def _filter(xs, ys, lbls):\n",
        "    idxs = [i for (i, l) in enumerate(ys) if l in lbls]\n",
        "    return xs[idxs, :], ys[idxs]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKTBzMgjd2-t"
      },
      "source": [
        "def clear_gpu(model):\n",
        "    # Removes model from gpu and clears the memory\n",
        "    \n",
        "    model = model.to('cpu')\n",
        "    del model\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlkmeGs_d8Fd"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    # Basic dataset class to work with torch data loader\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "        assert len(X) == len(y), print(\"Number of examples don't match up\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "cBno2hhZeGjE",
        "outputId": "aff05e46-113c-43f8-a857-31a589c3140b"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Autoencoder(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, encoder_units, decoder_units, input_dim, output_dim):\n",
        "    \n",
        "    # Conventional super-class declaration\n",
        "    super(Autoencoder, self).__init__()\n",
        "\n",
        "    # Initialize lists to store layers\n",
        "    encoder = []\n",
        "    decoder = []\n",
        "\n",
        "    # Add input and output dimensions to layer list for encoder\n",
        "    self.encoder_units = [input_dim] + encoder_units\n",
        "    self.decoder_units = [encoder_units[-1]] + decoder_units + [output_dim]\n",
        "\n",
        "    # Compute the total no. of layers for the encoder/decoder\n",
        "    self.encoder_layers = len(self.encoder_units)\n",
        "    self.decoder_layers = len(self.decoder_units)\n",
        "\n",
        "    # Append the hidden layers for the encoder\n",
        "    for i in range(1, self.encoder_layers):\n",
        "      \n",
        "      # Add linear layer\n",
        "      layer = ('Linear{}'.format(i), nn.Linear(self.encoder_units[i-1], self.encoder_units[i]))\n",
        "      activation = ('RELU{}'.format(i), nn.ReLU(True))\n",
        "      \n",
        "      # Append\n",
        "      encoder.append(layer)\n",
        "      encoder.append(activation)\n",
        "    \n",
        "    # Append the hidden layers for the decoder\n",
        "    for i in range(1, self.decoder_layers - 1):\n",
        "      \n",
        "      # Add the layers\n",
        "      layer = ('Linear{}'.format(i), nn.Linear(self.decoder_units[i-1], self.decoder_units[i]))\n",
        "      activation = ('RELU{}'.format(i), nn.ReLU(True))\n",
        "      \n",
        "      # Append to the lists\n",
        "      decoder.append(layer)\n",
        "      decoder.append(activation)\n",
        "\n",
        "    # Create final output layer\n",
        "    i = self.decoder_layers - 1\n",
        "    layer = ('Linear{}'.format(i), nn.Linear(self.decoder_units[i-1], self.decoder_units[i]))\n",
        "    activation = ('Sigmoid{}'.format(i), nn.Sigmoid())\n",
        "    \n",
        "    # Append to decoder list\n",
        "    decoder.append(layer)\n",
        "    decoder.append(activation)\n",
        "    \n",
        "    # Wrap this in a container and declare the encoder/decoder\n",
        "    self.encoder = nn.Sequential(OrderedDict(encoder))\n",
        "    self.decoder = nn.Sequential(OrderedDict(decoder))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    # First encode the noisy image and then decode\n",
        "    x=self.encoder(x)\n",
        "    x=self.decoder(x)\n",
        "    \n",
        "    return x\n",
        "'''\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.encoder_hidden_layer = nn.Linear(\n",
        "            in_features=kwargs[\"input_shape\"], out_features=128\n",
        "        )\n",
        "        self.encoder_output_layer = nn.Linear(\n",
        "            in_features=128, out_features=128\n",
        "        )\n",
        "        self.decoder_hidden_layer = nn.Linear(\n",
        "            in_features=128, out_features=128\n",
        "        )\n",
        "        self.decoder_output_layer = nn.Linear(\n",
        "            in_features=128, out_features=kwargs[\"input_shape\"]\n",
        "        )\n",
        "\n",
        "    def forward(self, features):\n",
        "        activation = self.encoder_hidden_layer(features)\n",
        "        activation = torch.relu(activation)\n",
        "        code = self.encoder_output_layer(activation)\n",
        "        code = torch.relu(code)\n",
        "        activation = self.decoder_hidden_layer(code)\n",
        "        activation = torch.relu(activation)\n",
        "        activation = self.decoder_output_layer(activation)\n",
        "        reconstructed = torch.sigmoid(activation)\n",
        "        return reconstructed\n",
        "\n",
        "      '''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nclass Autoencoder(nn.Module):\\n    def __init__(self, **kwargs):\\n        super().__init__()\\n        self.encoder_hidden_layer = nn.Linear(\\n            in_features=kwargs[\"input_shape\"], out_features=128\\n        )\\n        self.encoder_output_layer = nn.Linear(\\n            in_features=128, out_features=128\\n        )\\n        self.decoder_hidden_layer = nn.Linear(\\n            in_features=128, out_features=128\\n        )\\n        self.decoder_output_layer = nn.Linear(\\n            in_features=128, out_features=kwargs[\"input_shape\"]\\n        )\\n\\n    def forward(self, features):\\n        activation = self.encoder_hidden_layer(features)\\n        activation = torch.relu(activation)\\n        code = self.encoder_output_layer(activation)\\n        code = torch.relu(code)\\n        activation = self.decoder_hidden_layer(code)\\n        activation = torch.relu(activation)\\n        activation = self.decoder_output_layer(activation)\\n        reconstructed = torch.sigmoid(activation)\\n        return reconstructed\\n\\n      '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4UQKiiHXdo9"
      },
      "source": [
        "train_images, train_labels = load_mnist('data', 'train')\n",
        "test_images, test_labels = load_mnist('data', 't10k')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3IvlnM8YIKi"
      },
      "source": [
        "dataloader_params = {'batch_size': 1024, 'shuffle': True, 'num_workers': 6}\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxI3hJSWHKWE"
      },
      "source": [
        "train_images, train_labels = load_mnist('data', 'train')\n",
        "test_images, test_labels = load_mnist('data', 't10k')\n",
        "\n",
        "val_images = train_images[50000:]\n",
        "val_labels = train_labels[50000:]\n",
        "\n",
        "train_images = train_images[:50000]\n",
        "train_labels = train_labels[:50000]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeT_kOZxHTE4"
      },
      "source": [
        "#fashion mnist 1\n",
        "X_train1, y_train1 = _filter(train_images, train_labels, [0, 1, 4, 5, 8])\n",
        "X_val1, y_val1 = _filter(val_images, val_labels, [0, 1, 4, 5, 8])\n",
        "X_test1, y_test1 = _filter(test_images, test_labels, [0, 1, 4, 5, 8])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5URqDA-IHoRL"
      },
      "source": [
        "#fashion mnist 2\n",
        "X_train2, y_train2 = _filter(train_images, train_labels, [2, 3, 6, 7, 9])\n",
        "X_val2, y_val2 = _filter(val_images, val_labels, [2, 3, 6, 7, 9])\n",
        "X_test2, y_test2 = _filter(test_images, test_labels, [2, 3, 6, 7, 9])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rw-_6BOHrQs"
      },
      "source": [
        "#creating autoencoder train and validation set\n",
        "x_train_autoenc = np.vstack((X_train1 ,X_train2 ,X_val2 ,X_test2))\n",
        "x_train_autoenc = x_train_autoenc/255.0\n",
        "\n",
        "y_train_autoenc = np.hstack((y_train1 ,y_train2 ,y_val2 ,y_test2))\n",
        "x_val_autoenc = np.vstack((X_val1 , X_test1))\n",
        "x_val_autoenc = x_val_autoenc/255.0\n",
        "y_val_autoenc = np.hstack((y_val1 , y_test1))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Q7vrix2UNCTZ",
        "outputId": "550fa4f9-805c-45e5-ab39-e6d4ccdcfef3"
      },
      "source": [
        "train_data_auto_enc = Dataset(x_train_autoenc, y_train_autoenc)\n",
        "train_generator_auto_enc = torch.utils.data.DataLoader(train_data_auto_enc, **dataloader_params)\n",
        "val_data_auto_enc = Dataset(x_val_autoenc,y_val_autoenc)\n",
        "val_generator_auto_enc = torch.utils.data.DataLoader(val_data_auto_enc, **dataloader_params)\n",
        "'''\n",
        "x_train_autoenc = torch.from_numpy(x_train_autoenc).type(torch.FloatTensor).to(device)\n",
        "y_train_autoenc = torch.Tensor(y_train_autoenc).type(torch.LongTensor).to(device)\n",
        "\n",
        "X_val_autoenc = torch.from_numpy(x_val_autoenc).type(torch.FloatTensor).to(device)\n",
        "y_val_autoenc = torch.Tensor(y_val_autoenc).type(torch.LongTensor).to(device)\n",
        "'''\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nx_train_autoenc = torch.from_numpy(x_train_autoenc).type(torch.FloatTensor).to(device)\\ny_train_autoenc = torch.Tensor(y_train_autoenc).type(torch.LongTensor).to(device)\\n\\nX_val_autoenc = torch.from_numpy(x_val_autoenc).type(torch.FloatTensor).to(device)\\ny_val_autoenc = torch.Tensor(y_val_autoenc).type(torch.LongTensor).to(device)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naVKge_eOQn8"
      },
      "source": [
        "\n",
        "encoder_units = [256]\n",
        "decoder_units = [256]\n",
        "input_dim = 784\n",
        "output_dim = 784\n",
        "net = Autoencoder(encoder_units, decoder_units, input_dim, output_dim)\n",
        "#net = Autoencoder(input_shape = 784)\n",
        "net.to(device)\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "#optimizer = torch.optim.Adam(net.parameters(),lr = 0.7)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.2,momentum = 0.9)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZiwkDnTrm9h",
        "outputId": "b3d5f548-0aa6-4a60-f542-0f20dfdd0ce5"
      },
      "source": [
        "net.parameters()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f72701c8eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF0tLsiLl4Zr",
        "outputId": "4edb3be0-3621-4a2a-bc34-eb4a5d5a5f43"
      },
      "source": [
        "device"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imV6BgOMP8wS",
        "outputId": "d6d3f191-f423-494b-a18b-870071759e8e"
      },
      "source": [
        "#training routine for autoencoder\n",
        "epochs = 40\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  val_loss = 0.0\n",
        "  preds = []\n",
        "  for i, data in enumerate(train_generator_auto_enc):\n",
        "              \n",
        "              # Get the inputs: data is a list of [inputs, labels]\n",
        "              x, _ = data\n",
        "              #print(x.shape)\n",
        "              # Initialize container for noisy images\n",
        "              #noisy_images = []\n",
        "\n",
        "              # Now get noisy images\n",
        "              \n",
        "              \n",
        "\n",
        "              # Send the inputs and labels to the memory of the device\n",
        "              #noisy_images, flat_clean_imgs = noisy_images.to(device), flat_clean_imgs.to(device)\n",
        "\n",
        "              # Zero the parameter gradients\n",
        "              #x.to(device)\n",
        "              x = x.type(torch.FloatTensor)\n",
        "              x=x.to(device)\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # Forward\n",
        "              pred_x = net(x)\n",
        "              preds.append((pred_x[0],x[0]))\n",
        "              # Calculate loss\n",
        "              #print(pred_x[0],x[0])\n",
        "              loss = loss_fn(pred_x,x)\n",
        "\n",
        "              # Backward\n",
        "              loss.backward()\n",
        "              \n",
        "              # Optimize\n",
        "              optimizer.step()\n",
        "\n",
        "              # Add to running loss\n",
        "              running_loss += loss.item()\n",
        "  running_loss = (running_loss)/len(train_generator_auto_enc)\n",
        "  \n",
        "  for j,data in enumerate(val_generator_auto_enc):\n",
        "    x_val , _  = data \n",
        "    with torch.no_grad():\n",
        "      x_val = x_val.type(torch.FloatTensor)\n",
        "      x_val = x_val.to(device)\n",
        "      pred_x = net(x_val)\n",
        "      loss = loss_fn(pred_x,x_val)\n",
        "      val_loss+=loss.item()\n",
        "  val_loss = val_loss/len(val_generator_auto_enc)\n",
        "  print(\"epoch: \",epoch, \"train_loss: \",running_loss,\"val_loss:\",val_loss)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0 train_loss:  0.15552750242463612 val_loss: 0.1134523831307888\n",
            "epoch:  1 train_loss:  0.09538349483982991 val_loss: 0.09492865055799485\n",
            "epoch:  2 train_loss:  0.08914630064519785 val_loss: 0.08996298611164093\n",
            "epoch:  3 train_loss:  0.07976031265521454 val_loss: 0.08001450225710868\n",
            "epoch:  4 train_loss:  0.06960434365575596 val_loss: 0.07283783480525016\n",
            "epoch:  5 train_loss:  0.0622909636694496 val_loss: 0.06485459506511689\n",
            "epoch:  6 train_loss:  0.056523301149323836 val_loss: 0.06031922064721584\n",
            "epoch:  7 train_loss:  0.05365908985673371 val_loss: 0.05795841105282307\n",
            "epoch:  8 train_loss:  0.05170099670856686 val_loss: 0.05608433969318867\n",
            "epoch:  9 train_loss:  0.049910834406392046 val_loss: 0.05433360785245896\n",
            "epoch:  10 train_loss:  0.04811389302298174 val_loss: 0.052611615508794785\n",
            "epoch:  11 train_loss:  0.04627082162236763 val_loss: 0.05089206248521805\n",
            "epoch:  12 train_loss:  0.04441667714361417 val_loss: 0.04902545288205147\n",
            "epoch:  13 train_loss:  0.04264274580498873 val_loss: 0.04722071848809719\n",
            "epoch:  14 train_loss:  0.04099636316552001 val_loss: 0.045442777872085574\n",
            "epoch:  15 train_loss:  0.03943666758931289 val_loss: 0.043604903295636176\n",
            "epoch:  16 train_loss:  0.03791300523079048 val_loss: 0.0417934462428093\n",
            "epoch:  17 train_loss:  0.03641136735677719 val_loss: 0.03997723311185837\n",
            "epoch:  18 train_loss:  0.03494862864835788 val_loss: 0.03823337480425835\n",
            "epoch:  19 train_loss:  0.03357926604606337 val_loss: 0.03664212822914124\n",
            "epoch:  20 train_loss:  0.03233453628244037 val_loss: 0.03531399071216583\n",
            "epoch:  21 train_loss:  0.03125425188218133 val_loss: 0.034116684645414355\n",
            "epoch:  22 train_loss:  0.0303171785011635 val_loss: 0.033096412941813466\n",
            "epoch:  23 train_loss:  0.02949848575359684 val_loss: 0.03220661953091621\n",
            "epoch:  24 train_loss:  0.028810826903682644 val_loss: 0.031487905979156496\n",
            "epoch:  25 train_loss:  0.02820617853963779 val_loss: 0.03084105234593153\n",
            "epoch:  26 train_loss:  0.027687220534278176 val_loss: 0.03029526900500059\n",
            "epoch:  27 train_loss:  0.027225262880072754 val_loss: 0.029758152551949024\n",
            "epoch:  28 train_loss:  0.026823327608280264 val_loss: 0.0293382054194808\n",
            "epoch:  29 train_loss:  0.026469438289434224 val_loss: 0.028979452699422835\n",
            "epoch:  30 train_loss:  0.026167584677874032 val_loss: 0.02864638026803732\n",
            "epoch:  31 train_loss:  0.02588654748337754 val_loss: 0.028338436037302017\n",
            "epoch:  32 train_loss:  0.02563255138190116 val_loss: 0.028084925189614297\n",
            "epoch:  33 train_loss:  0.025396452427415523 val_loss: 0.027887202613055707\n",
            "epoch:  34 train_loss:  0.025167884020987203 val_loss: 0.027572318352758883\n",
            "epoch:  35 train_loss:  0.024974592787734534 val_loss: 0.02736486177891493\n",
            "epoch:  36 train_loss:  0.024763458613621985 val_loss: 0.027150659635663033\n",
            "epoch:  37 train_loss:  0.024575792568719994 val_loss: 0.02698249612003565\n",
            "epoch:  38 train_loss:  0.024384343333668627 val_loss: 0.026745841093361377\n",
            "epoch:  39 train_loss:  0.024200979272945452 val_loss: 0.026544930040836336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Yusx0RAc0kt8",
        "outputId": "86312562-e260-4ac1-b168-f84c63ce0f21"
      },
      "source": [
        "a,b = preds[-2]\n",
        "a = a.cpu().detach().numpy()\n",
        "b = b.cpu().detach().numpy()\n",
        "plt.imshow(a.reshape(28,28))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f72fdb2ca90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "F48sIOb3HjHD",
        "outputId": "549bd128-d62a-4c85-8c06-3e7e30d6d039"
      },
      "source": [
        "plt.imshow(b.reshape(28,28))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f72fdac3e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWEwxlQSmMSd",
        "outputId": "72356559-3162-44b3-e057-2c08d1d4df9d"
      },
      "source": [
        "net.encoder.Linear1.weight"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 2.5421e-02, -2.1288e-04,  6.1642e-02,  ..., -3.9452e-02,\n",
              "         -7.3265e-02, -2.5514e-02],\n",
              "        [ 2.5733e-02, -4.9902e-02, -6.8294e-02,  ..., -4.5370e-02,\n",
              "         -7.7490e-02,  8.3840e-02],\n",
              "        [ 1.0899e-02, -6.9107e-02, -8.0908e-02,  ..., -1.0650e-01,\n",
              "         -5.5905e-02, -8.5170e-02],\n",
              "        ...,\n",
              "        [ 3.3303e-02, -4.5017e-01, -2.8376e-01,  ..., -1.4239e-01,\n",
              "         -1.4423e-01,  3.4204e-02],\n",
              "        [-2.7679e-02, -1.1544e-02,  2.1800e-02,  ..., -4.8923e-02,\n",
              "         -2.1646e-02,  2.2567e-02],\n",
              "        [ 9.2440e-04, -8.2279e-02, -6.2101e-02,  ..., -9.2137e-02,\n",
              "         -7.1895e-02, -2.4563e-02]], device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xshshIRyiSVj"
      },
      "source": [
        "# creating a mlp with autoencoder initialized weights\n",
        "'''\n",
        "class pretrained_mlp(torch.nn.Module):\n",
        "  def __init__(self, encoder_layers,encoder_weights, mlp_hidden_layer, input_dim, output_dim,pretrained):\n",
        "    super(pretrained_mlp, self).__init__()\n",
        "    self.mlp_hidden_layer = mlp_hidden_layer\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.encoder_units = [input_dim] + encoder_layers\n",
        "    self.encoder_layers = len(self.encoder_units)\n",
        "    self.pretrained = pretrained\n",
        "    encoder = []\n",
        "    mlp = []\n",
        "    # Append the hidden layers for the encoder\n",
        "    for i in range(1, self.encoder_layers):\n",
        "      \n",
        "      # Add linear layer\n",
        "      layer = nn.Linear(self.encoder_units[i-1], self.encoder_units[i])\n",
        "      if pretrained :\n",
        "        layer.weight = encoder_weights[i-1]\n",
        "      layer = ('Linear{}'.format(i), layer)\n",
        "      activation = ('RELU{}'.format(i), nn.ReLU(True))\n",
        "      \n",
        "      # Append\n",
        "      encoder.append(layer)\n",
        "      encoder.append(activation)\n",
        "    self.mlp_units = [encoder_layers[-1]]+self.mlp_hidden_layer \n",
        "    self.mlp_layers = len(self.mlp_units)\n",
        "    print(\"mlp_units: \",self.mlp_units)\n",
        "    for i in range(1,self.mlp_layers):\n",
        "      layer = ('Linear{}'.format(i), nn.Linear(self.mlp_units[i-1], self.mlp_units[i]))\n",
        "      activation = ('RELU{}'.format(i), nn.ReLU(True))\n",
        "      print(\"layer:\",layer)\n",
        "      mlp.append(layer)\n",
        "      mlp.append(activation)\n",
        "    output_layer =  ('Linear{}'.format(i+1), nn.Linear(self.mlp_units[-1],self.output_dim))\n",
        "    activation = ('sigmoid{}'.format(i+1), nn.Sigmoid())\n",
        "    mlp.append(output_layer)\n",
        "    mlp.append(activation)\n",
        "    self.encoder = nn.Sequential(OrderedDict(encoder))\n",
        "    self.mlp = nn.Sequential(OrderedDict(mlp))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \n",
        "    # First encode the noisy image and then decode\n",
        "    x=self.encoder(x)\n",
        "    x=self.mlp(x)\n",
        "    \n",
        "    return x\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7iHQG-Irhmw"
      },
      "source": [
        "#creating mlp  dataloaders for fashion mnist 1\n",
        "'''\n",
        "x_train_mlp = X_train1/255.0\n",
        "\n",
        "y_train_mlp = y_train1\n",
        "x_val_mlp = X_val1/255.0\n",
        "y_val_mlp = y_val1 \n",
        "\n",
        "train_data_mlp = Dataset(x_train_mlp, y_train_mlp)\n",
        "train_loader_mlp = torch.utils.data.DataLoader(train_data_mlp, **dataloader_params)\n",
        "val_data_mlp = Dataset(x_val_mlp, y_val_mlp)\n",
        "val_loader_mlp = torch.utils.data.DataLoader(val_data_mlp, **dataloader_params)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIEI85541WYE",
        "outputId": "023c0b65-e7c1-466b-d5aa-0a631c8a6391"
      },
      "source": [
        "y_val1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLSbAWWIti9-",
        "outputId": "ab5cb168-9472-4a27-f6c4-c6525b9c5532"
      },
      "source": [
        "'''\n",
        "encoder_units = [256]\n",
        "mlp_units = [128,64]\n",
        "input_dim = 784\n",
        "output_dim = 10\n",
        "encoder_weights = [net.encoder.Linear1.weight]\n",
        "mlp_net = pretrained_mlp(encoder_units,encoder_weights, mlp_units, input_dim, output_dim,pretrained = True)\n",
        "#net = Autoencoder(input_shape = 784)\n",
        "mlp_net.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(net.parameters(),lr = 0.7)\n",
        "optimizer = torch.optim.SGD(mlp_net.parameters(), lr=0.2,momentum = 0.9)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mlp_units:  [256, 128, 64]\n",
            "layer: ('Linear1', Linear(in_features=256, out_features=128, bias=True))\n",
            "layer: ('Linear2', Linear(in_features=128, out_features=64, bias=True))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hHiQV62zV9A",
        "outputId": "8efd3250-acd4-4710-9466-c456f745f4ba"
      },
      "source": [
        "mlp_net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pretrained_mlp(\n",
              "  (encoder): Sequential(\n",
              "    (Linear1): Linear(in_features=784, out_features=256, bias=True)\n",
              "    (RELU1): ReLU(inplace=True)\n",
              "  )\n",
              "  (mlp): Sequential(\n",
              "    (Linear1): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (RELU1): ReLU(inplace=True)\n",
              "    (Linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (RELU2): ReLU(inplace=True)\n",
              "    (Linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              "    (sigmoid3): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jnq5a3hD21b"
      },
      "source": [
        "class mlp_net (torch.nn.Module) :\n",
        "  def __init__(self,input_dim,output_dim,hidden_dim,encoder_weight,pretrained):\n",
        "    super(mlp_net, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.layer1 = nn.Linear(self.input_dim, self.hidden_dim)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    \n",
        "    if pretrained ==True :\n",
        "      self.layer1.weight = encoder_weight\n",
        "    #print(\"mlp_layer weight: \",self.layer1.weight)\n",
        "    self.layer2 = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "    self.activation2 = nn.Sigmoid()\n",
        "  def forward(self,x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.activation1(x)\n",
        "    out = self.layer2(x)\n",
        "    out = self.activation2(out)\n",
        "    return out\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9K4UQqSFTfc",
        "outputId": "89e420cc-63d3-4731-b11a-52867eb0b5fe"
      },
      "source": [
        "mlp_net(input_dim,output_dim,hidden_dim,encoder_weight,pretrained = True)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mlp_layer weight:  Parameter containing:\n",
            "tensor([[ 2.5421e-02, -2.1288e-04,  6.1642e-02,  ..., -3.9451e-02,\n",
            "         -7.3265e-02, -2.5514e-02],\n",
            "        [ 2.5733e-02, -4.9902e-02, -6.8295e-02,  ..., -4.5366e-02,\n",
            "         -7.7489e-02,  8.3840e-02],\n",
            "        [ 1.0899e-02, -6.9107e-02, -8.0908e-02,  ..., -1.0651e-01,\n",
            "         -5.5908e-02, -8.5170e-02],\n",
            "        ...,\n",
            "        [ 3.3303e-02, -4.5017e-01, -2.8376e-01,  ..., -1.4239e-01,\n",
            "         -1.4423e-01,  3.4204e-02],\n",
            "        [-2.7679e-02, -1.1544e-02,  2.1800e-02,  ..., -4.8923e-02,\n",
            "         -2.1646e-02,  2.2567e-02],\n",
            "        [ 9.2440e-04, -8.2279e-02, -6.2101e-02,  ..., -9.2129e-02,\n",
            "         -7.1888e-02, -2.4562e-02]], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mlp_net(\n",
              "  (layer1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (activation1): ReLU()\n",
              "  (layer2): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjBsT3N1gT-i",
        "outputId": "9eca6ef4-3202-4bf8-e321-a099275f500b"
      },
      "source": [
        "net.encoder.Linear1.weight"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 2.5421e-02, -2.1288e-04,  6.1642e-02,  ..., -3.9452e-02,\n",
              "         -7.3265e-02, -2.5514e-02],\n",
              "        [ 2.5733e-02, -4.9902e-02, -6.8294e-02,  ..., -4.5370e-02,\n",
              "         -7.7490e-02,  8.3840e-02],\n",
              "        [ 1.0899e-02, -6.9107e-02, -8.0908e-02,  ..., -1.0650e-01,\n",
              "         -5.5905e-02, -8.5170e-02],\n",
              "        ...,\n",
              "        [ 3.3303e-02, -4.5017e-01, -2.8376e-01,  ..., -1.4239e-01,\n",
              "         -1.4423e-01,  3.4204e-02],\n",
              "        [-2.7679e-02, -1.1544e-02,  2.1800e-02,  ..., -4.8923e-02,\n",
              "         -2.1646e-02,  2.2567e-02],\n",
              "        [ 9.2440e-04, -8.2279e-02, -6.2101e-02,  ..., -9.2137e-02,\n",
              "         -7.1895e-02, -2.4563e-02]], device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYaWDahLFxY2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "626cb9bc-661e-499a-87fe-79641e37795b"
      },
      "source": [
        "input_dim = 784\n",
        "output_dim = 10\n",
        "hidden_dim = 256\n",
        "encoder_weight = net.encoder.Linear1.weight\n",
        "#encoder_weight = 0\n",
        "'''\n",
        "mlp_net2 = mlp_net(input_dim,output_dim,hidden_dim,encoder_weight,pretrained = True)\n",
        "#net = Autoencoder(input_shape = 784)\n",
        "mlp_net2.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(net.parameters(),lr = 0.7)\n",
        "optimizer = torch.optim.Adam(mlp_net2.parameters(), lr=0.01)\n",
        "'''"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nmlp_net2 = mlp_net(input_dim,output_dim,hidden_dim,encoder_weight,pretrained = True)\\n#net = Autoencoder(input_shape = 784)\\nmlp_net2.to(device)\\n\\nloss_fn = torch.nn.CrossEntropyLoss()\\n#optimizer = torch.optim.Adam(net.parameters(),lr = 0.7)\\noptimizer = torch.optim.Adam(mlp_net2.parameters(), lr=0.01)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgK9_2ATgsMM"
      },
      "source": [
        "import random\n",
        "#taking on 5% of data for training\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTq8HLk4H6Nr"
      },
      "source": [
        "\n",
        "def relabel_data(y):\n",
        "  for i in range(len(y)):\n",
        "    if y[i]==5 :\n",
        "      y[i] = 2\n",
        "    if y[i]==8 :\n",
        "      y[i] = 3\n",
        "  return y "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgeCraSQPaOw",
        "outputId": "f6bd11fd-3603-403e-8628-6a6151d43c4c"
      },
      "source": [
        "y_train1"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 5, 5, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "3nKKxosZkMF-",
        "outputId": "fe7d75e2-979c-4c99-8367-efbb2a89f617"
      },
      "source": [
        "\n",
        "#net = Autoencoder(input_shape = 784)\n",
        "pretrained = False\n",
        "data_percent_list = [0.05,0.1,0.2,0.4,0.6,0.8]\n",
        "data_percent = 0.8\n",
        "test_acc_true = []\n",
        "val_acc_true = []\n",
        "x_train_mlp = X_train1\n",
        "y_train_mlp = y_train1\n",
        "x_val_mlp = X_val1\n",
        "y_val_mlp = y_val1 \n",
        "#temp = list(zip(x_train_mlp, y_train_mlp)) \n",
        "#random.shuffle(temp) \n",
        "x_train_mlp, y_train_mlp = zip(*temp)\n",
        "size = len(x_train_mlp)\n",
        "#for data_percent in data_percent_list :\n",
        "\n",
        "#optimizer = torch.optim.Adam(net.parameters(),lr = 0.7)\n",
        "val_data_mlp = Dataset(x_val_mlp, y_val_mlp)\n",
        "val_loader_mlp = torch.utils.data.DataLoader(val_data_mlp, **dataloader_params)\n",
        "test_data_mlp = Dataset(X_test1, y_test1)\n",
        "test_loader_mlp = torch.utils.data.DataLoader(test_data_mlp, **dataloader_params)\n",
        "\n",
        "train_data_mlp = Dataset(x_train_mlp[0:int(data_percent*size)], y_train_mlp[0:int(data_percent*size)])\n",
        "train_loader_mlp = torch.utils.data.DataLoader(train_data_mlp, **dataloader_params)  \n",
        "val_acc,test_acc  = train_mlp(input_dim,output_dim,hidden_dim,encoder_weight,pretrained,train_loader_mlp,test_loader_mlp,val_loader_mlp,20)\n",
        "val_acc_true.append(val_acc)\n",
        "test_acc_true.append(test_acc)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0 train_loss:  2.125314939022064\n",
            "epoch:  0 test_loss:  2.518496561050415 acc:  0.20333986477395047\n",
            "epoch:  1 train_loss:  2.1203976392745973\n",
            "epoch:  1 test_loss:  2.518626165390015 acc:  0.20395902011571582\n",
            "epoch:  2 train_loss:  2.1185805201530457\n",
            "epoch:  2 test_loss:  2.5185225009918213 acc:  0.20347967404467168\n",
            "epoch:  3 train_loss:  2.1201180815696716\n",
            "epoch:  3 test_loss:  2.5182891368865965 acc:  0.20415874764531755\n",
            "epoch:  4 train_loss:  2.1189998626708983\n",
            "epoch:  4 test_loss:  2.5182891368865965 acc:  0.20393904736275564\n",
            "epoch:  5 train_loss:  2.1208635568618774\n",
            "epoch:  5 test_loss:  2.518133592605591 acc:  0.20377926533907428\n",
            "epoch:  6 train_loss:  2.120164716243744\n",
            "epoch:  6 test_loss:  2.5184446811676025 acc:  0.20399896562163616\n",
            "epoch:  7 train_loss:  2.1202112674713134\n",
            "epoch:  7 test_loss:  2.518133592605591 acc:  0.20377926533907428\n",
            "epoch:  8 train_loss:  2.119931697845459\n",
            "epoch:  8 test_loss:  2.5181854248046873 acc:  0.2037592925861141\n",
            "epoch:  9 train_loss:  2.118999922275543\n",
            "epoch:  9 test_loss:  2.5182631969451905 acc:  0.20349964679763186\n",
            "epoch:  10 train_loss:  2.1189998984336853\n",
            "epoch:  10 test_loss:  2.518418788909912 acc:  0.20393904736275564\n",
            "epoch:  11 train_loss:  2.119512379169464\n",
            "epoch:  11 test_loss:  2.518652105331421 acc:  0.20357953780947255\n",
            "epoch:  12 train_loss:  2.1189067125320435\n",
            "epoch:  12 test_loss:  2.5182631969451905 acc:  0.2037592925861141\n",
            "epoch:  13 train_loss:  2.1190930724143984\n",
            "epoch:  13 test_loss:  2.518600273132324 acc:  0.20365942882131324\n",
            "epoch:  14 train_loss:  2.119605600833893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-780a358bdab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtrain_data_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_mlp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_percent\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mlp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_percent\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtrain_loader_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdataloader_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader_mlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader_mlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader_mlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mval_acc_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtest_acc_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-46b5bd4f2446>\u001b[0m in \u001b[0;36mtrain_mlp\u001b[0;34m(input_dim, output_dim, hidden_dim, encoder_weight, pretrained, train_loader_mlp, test_loader_mlp, val_loader_mlp, epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader_mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdCJ2MY2P41J",
        "outputId": "dc92ca1f-2ffc-4c31-cc1c-b4b0df218df7"
      },
      "source": [
        "set(y_train1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 4, 5, 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1iMSn4m8j62",
        "outputId": "727ab54d-4a43-4f0f-b80e-dd6f0e0b8987"
      },
      "source": [
        "print(val_acc_true , test_acc_true)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.7810163736343383], [1.5451267957687378], [1.3903373241424561], [1.3137418985366822], [1.2803945779800414], [1.402147603034973]] [[1.8347511053085328], [1.5147045612335206], [1.3889920711517334], [1.3459396600723266], [1.255441164970398], [1.445418119430542]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "958rZzU34JeA",
        "outputId": "768aef21-1f39-4fd7-a4dd-3c89257daa61"
      },
      "source": [
        "pretrained = False\n",
        "val_acc_false = []\n",
        "test_acc_false = []\n",
        "for data_percent in data_percent_list :\n",
        "  train_data_mlp = Dataset(x_train_mlp[0:int(data_percent*size)], y_train_mlp[0:int(data_percent*size)])\n",
        "  train_loader_mlp = torch.utils.data.DataLoader(train_data_mlp, **dataloader_params)  \n",
        "  val_acc,test_acc  = train_mlp(input_dim,output_dim,hidden_dim,encoder_weight,pretrained,train_loader_mlp,test_loader_mlp,val_loader_mlp,20)\n",
        "  val_acc_false.append(val_acc)\n",
        "  test_acc_false.append(test_acc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0 train_loss:  1.5916569232940674\n",
            "epoch:  0 test_loss:  1.568542718887329 acc:  0.3853418914827772\n",
            "epoch:  1 train_loss:  1.6107159852981567\n",
            "epoch:  1 test_loss:  1.7049563646316528 acc:  0.19854577334499462\n",
            "epoch:  2 train_loss:  1.6799439191818237\n",
            "epoch:  2 test_loss:  1.7046711206436158 acc:  0.1977668359795479\n",
            "epoch:  3 train_loss:  1.6851754784584045\n",
            "epoch:  3 test_loss:  1.7043859720230103 acc:  0.19822620929763185\n",
            "epoch:  4 train_loss:  1.7026141285896301\n",
            "epoch:  4 test_loss:  1.7048526525497436 acc:  0.1982661548035522\n",
            "epoch:  5 train_loss:  1.6921510100364685\n",
            "epoch:  5 test_loss:  1.705578589439392 acc:  0.19802648176803012\n",
            "epoch:  6 train_loss:  1.6869194507598877\n",
            "epoch:  6 test_loss:  1.7046452283859252 acc:  0.19822620929763185\n",
            "epoch:  7 train_loss:  1.7008703351020813\n",
            "epoch:  7 test_loss:  1.704878568649292 acc:  0.19780678148546824\n",
            "epoch:  8 train_loss:  1.6973824501037598\n",
            "epoch:  8 test_loss:  1.7049045085906982 acc:  0.19842593682723358\n",
            "epoch:  9 train_loss:  1.7008702754974365\n",
            "epoch:  9 test_loss:  1.7042303323745727 acc:  0.19822620929763185\n",
            "epoch:  10 train_loss:  1.7078458070755005\n",
            "epoch:  10 test_loss:  1.7051119089126587 acc:  0.19778680873250806\n",
            "epoch:  11 train_loss:  1.7148211598396301\n",
            "epoch:  11 test_loss:  1.7049044847488404 acc:  0.19836601856835306\n",
            "epoch:  12 train_loss:  1.702614188194275\n",
            "epoch:  12 test_loss:  1.705034112930298 acc:  0.19832607306243272\n",
            "epoch:  13 train_loss:  1.699126422405243\n",
            "epoch:  13 test_loss:  1.7046971082687379 acc:  0.1979865362621098\n",
            "epoch:  14 train_loss:  1.704357922077179\n",
            "epoch:  14 test_loss:  1.704878568649292 acc:  0.19842593682723358\n",
            "epoch:  15 train_loss:  1.683431625366211\n",
            "epoch:  15 test_loss:  1.7044897317886352 acc:  0.19820623654467168\n",
            "epoch:  16 train_loss:  1.6938947439193726\n",
            "epoch:  16 test_loss:  1.704956316947937 acc:  0.19824618205059202\n",
            "epoch:  17 train_loss:  1.6973825693130493\n",
            "epoch:  17 test_loss:  1.7050082445144654 acc:  0.1981063727798708\n",
            "epoch:  18 train_loss:  1.6904070973396301\n",
            "epoch:  18 test_loss:  1.704437804222107 acc:  0.19844590958019376\n",
            "epoch:  19 train_loss:  1.7061018347740173\n",
            "epoch:  19 test_loss:  1.7050600528717041 acc:  0.19824618205059202\n",
            "epoch:  0 train_loss:  1.6953997611999512\n",
            "epoch:  0 test_loss:  1.509852647781372 acc:  0.3075255230758881\n",
            "epoch:  1 train_loss:  1.4502435127894084\n",
            "epoch:  1 test_loss:  1.3970409870147704 acc:  0.5072787018972014\n",
            "epoch:  2 train_loss:  1.3764909108479817\n",
            "epoch:  2 test_loss:  1.3378162622451781 acc:  0.500844532090958\n",
            "epoch:  3 train_loss:  1.367879311243693\n",
            "epoch:  3 test_loss:  1.39783673286438 acc:  0.5135930351856836\n",
            "epoch:  4 train_loss:  1.4157106479008992\n",
            "epoch:  4 test_loss:  1.392733883857727 acc:  0.5209039037271259\n",
            "epoch:  5 train_loss:  1.3697293599446614\n",
            "epoch:  5 test_loss:  1.3582803010940552 acc:  0.6900575635764262\n",
            "epoch:  6 train_loss:  1.3709770441055298\n",
            "epoch:  6 test_loss:  1.4220022439956665 acc:  0.5938286295748116\n",
            "epoch:  7 train_loss:  1.426339864730835\n",
            "epoch:  7 test_loss:  1.4533014297485352 acc:  0.5335636857508074\n",
            "epoch:  8 train_loss:  1.4368289311726887\n",
            "epoch:  8 test_loss:  1.4390251159667968 acc:  0.528987192209365\n",
            "epoch:  9 train_loss:  1.4282939036687214\n",
            "epoch:  9 test_loss:  1.427937889099121 acc:  0.5490644342034445\n",
            "epoch:  10 train_loss:  1.4172453880310059\n",
            "epoch:  10 test_loss:  1.4436841249465941 acc:  0.5310801264800861\n",
            "epoch:  11 train_loss:  1.4300481081008911\n",
            "epoch:  11 test_loss:  1.4740511417388915 acc:  0.4879383493675996\n",
            "epoch:  12 train_loss:  1.4421967665354412\n",
            "epoch:  12 test_loss:  1.4284605264663697 acc:  0.5468693235333693\n",
            "epoch:  13 train_loss:  1.4163366556167603\n",
            "epoch:  13 test_loss:  1.4410084009170532 acc:  0.45603366354951563\n",
            "epoch:  14 train_loss:  1.4370396534601848\n",
            "epoch:  14 test_loss:  1.456317925453186 acc:  0.3872327855893434\n",
            "epoch:  15 train_loss:  1.4796465635299683\n",
            "epoch:  15 test_loss:  1.5709762573242188 acc:  0.3837571060952637\n",
            "epoch:  16 train_loss:  1.554608980814616\n",
            "epoch:  16 test_loss:  1.4864631414413452 acc:  0.4973177643972013\n",
            "epoch:  17 train_loss:  1.4925824403762817\n",
            "epoch:  17 test_loss:  1.4883004426956177 acc:  0.4688555402314316\n",
            "epoch:  18 train_loss:  1.4954517682393391\n",
            "epoch:  18 test_loss:  1.4857715606689452 acc:  0.4693704167787944\n",
            "epoch:  19 train_loss:  1.5000649690628052\n",
            "epoch:  19 test_loss:  1.496643304824829 acc:  0.4403243575080732\n",
            "epoch:  0 train_loss:  1.6509304285049438\n",
            "epoch:  0 test_loss:  1.6985595226287842 acc:  0.306895225040366\n",
            "epoch:  1 train_loss:  1.6822171211242676\n",
            "epoch:  1 test_loss:  1.6508045196533203 acc:  0.39518950988966633\n",
            "epoch:  2 train_loss:  1.6346392154693603\n",
            "epoch:  2 test_loss:  1.6192988872528076 acc:  0.37814413179494083\n",
            "epoch:  3 train_loss:  1.6457128763198852\n",
            "epoch:  3 test_loss:  1.7045781373977662 acc:  0.19880100410387513\n",
            "epoch:  4 train_loss:  1.70563485622406\n",
            "epoch:  4 test_loss:  1.7046452283859252 acc:  0.19800650901506997\n",
            "epoch:  5 train_loss:  1.705743432044983\n",
            "epoch:  5 test_loss:  1.7047489643096925 acc:  0.19832607306243272\n",
            "epoch:  6 train_loss:  1.7053361177444457\n",
            "epoch:  6 test_loss:  1.7043341159820558 acc:  0.19858571885091497\n",
            "epoch:  7 train_loss:  1.7054176092147828\n",
            "epoch:  7 test_loss:  1.7045414924621582 acc:  0.19800650901506997\n",
            "epoch:  8 train_loss:  1.7053904771804809\n",
            "epoch:  8 test_loss:  1.7044637203216553 acc:  0.1979066452502691\n",
            "epoch:  9 train_loss:  1.7058520793914795\n",
            "epoch:  9 test_loss:  1.7049304485321044 acc:  0.19794659075618945\n",
            "epoch:  10 train_loss:  1.7057163953781127\n",
            "epoch:  10 test_loss:  1.7044896841049195 acc:  0.1984858550861141\n",
            "epoch:  11 train_loss:  1.7059336185455323\n",
            "epoch:  11 test_loss:  1.7045415401458741 acc:  0.19814631828579116\n",
            "epoch:  12 train_loss:  1.7049288034439087\n",
            "epoch:  12 test_loss:  1.7050859689712525 acc:  0.19836601856835306\n",
            "epoch:  13 train_loss:  1.7051732063293457\n",
            "epoch:  13 test_loss:  1.7049822807312012 acc:  0.19838599132131324\n",
            "epoch:  14 train_loss:  1.7056620597839356\n",
            "epoch:  14 test_loss:  1.7052934169769287 acc:  0.1984059640742734\n",
            "epoch:  15 train_loss:  1.7060149908065796\n",
            "epoch:  15 test_loss:  1.7046971321105957 acc:  0.19806642727395046\n",
            "epoch:  16 train_loss:  1.7056077003479004\n",
            "epoch:  16 test_loss:  1.7049304008483888 acc:  0.19808640002691064\n",
            "epoch:  17 train_loss:  1.7051189184188842\n",
            "epoch:  17 test_loss:  1.7045674324035645 acc:  0.1976270267088267\n",
            "epoch:  18 train_loss:  1.7053361177444457\n",
            "epoch:  18 test_loss:  1.7044119119644165 acc:  0.19888531014531755\n",
            "epoch:  19 train_loss:  1.7062322854995728\n",
            "epoch:  19 test_loss:  1.704774832725525 acc:  0.1983460458153929\n",
            "epoch:  0 train_loss:  1.5412932515144349\n",
            "epoch:  0 test_loss:  1.5089054346084594 acc:  0.35684623923573733\n",
            "epoch:  1 train_loss:  1.5449031233787536\n",
            "epoch:  1 test_loss:  1.5575734615325927 acc:  0.2860522907696448\n",
            "epoch:  2 train_loss:  1.5180574536323548\n",
            "epoch:  2 test_loss:  1.5304507970809937 acc:  0.3935826493541442\n",
            "epoch:  3 train_loss:  1.5451299548149109\n",
            "epoch:  3 test_loss:  1.538600254058838 acc:  0.3911146478067815\n",
            "epoch:  4 train_loss:  1.5339470386505127\n",
            "epoch:  4 test_loss:  1.5177989244461059 acc:  0.3954247678955866\n",
            "epoch:  5 train_loss:  1.5088822841644287\n",
            "epoch:  5 test_loss:  1.4984777212142943 acc:  0.3920157343245425\n",
            "epoch:  6 train_loss:  1.5003702878952025\n",
            "epoch:  6 test_loss:  1.4956906318664551 acc:  0.38675785454790096\n",
            "epoch:  7 train_loss:  1.4943722367286683\n",
            "epoch:  7 test_loss:  1.4998465061187745 acc:  0.36314501480086114\n",
            "epoch:  8 train_loss:  1.5000600457191466\n",
            "epoch:  8 test_loss:  1.4896005630493163 acc:  0.3756250420479009\n",
            "epoch:  9 train_loss:  1.4882052421569825\n",
            "epoch:  9 test_loss:  1.486635422706604 acc:  0.3891304073600646\n",
            "epoch:  10 train_loss:  1.4920660614967347\n",
            "epoch:  10 test_loss:  1.49013671875 acc:  0.3912788448600646\n",
            "epoch:  11 train_loss:  1.4885051131248475\n",
            "epoch:  11 test_loss:  1.4867932558059693 acc:  0.3758802728067815\n",
            "epoch:  12 train_loss:  1.4876680374145508\n",
            "epoch:  12 test_loss:  1.4883594036102294 acc:  0.3733168225242196\n",
            "epoch:  13 train_loss:  1.4843047857284546\n",
            "epoch:  13 test_loss:  1.482462739944458 acc:  0.3876501110064586\n",
            "epoch:  14 train_loss:  1.4875083208084106\n",
            "epoch:  14 test_loss:  1.4884064197540283 acc:  0.3917760612890205\n",
            "epoch:  15 train_loss:  1.4883954524993896\n",
            "epoch:  15 test_loss:  1.483178472518921 acc:  0.38585676803013996\n",
            "epoch:  16 train_loss:  1.4860651969909668\n",
            "epoch:  16 test_loss:  1.493709397315979 acc:  0.3690443353067815\n",
            "epoch:  17 train_loss:  1.4950313091278076\n",
            "epoch:  17 test_loss:  1.50076744556427 acc:  0.3602552728067815\n",
            "epoch:  18 train_loss:  1.5000692844390868\n",
            "epoch:  18 test_loss:  1.5042948246002197 acc:  0.3560738192949408\n",
            "epoch:  19 train_loss:  1.5017327308654784\n",
            "epoch:  19 test_loss:  1.5059486865997314 acc:  0.35357028727125944\n",
            "epoch:  0 train_loss:  1.5982989231745401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-35c4718fbdcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtrain_data_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_mlp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_percent\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mlp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_percent\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtrain_loader_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdataloader_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader_mlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader_mlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader_mlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mval_acc_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mtest_acc_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-46b5bd4f2446>\u001b[0m in \u001b[0;36mtrain_mlp\u001b[0;34m(input_dim, output_dim, hidden_dim, encoder_weight, pretrained, train_loader_mlp, test_loader_mlp, val_loader_mlp, epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader_mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mark_worker_as_unavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshutdown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m                         \u001b[0;31m# Existing mechanisms try to make the workers exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6j46JUe4fP9",
        "outputId": "53d4a1d3-ecc1-4681-935e-12d59b806b2f"
      },
      "source": [
        "print(val_acc_false,test_acc_false)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.792197608947754], [3.6840911388397215], [1.9142696142196656], [0.3417442739009857], [0.38419090360403063], [0.2452104151248932]] [[5.640351867675781], [3.0648836135864257], [1.793165683746338], [0.3250050783157349], [0.32778828144073485], [0.1633344456553459]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVKZdd-3p_Qq",
        "outputId": "c1599067-74d3-43fe-df6c-ebf0d46ec063"
      },
      "source": [
        "optimizer"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.01\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9JbLpieepj2",
        "outputId": "b8bb8cd7-4e77-4215-e133-a8474cfc3bcc"
      },
      "source": [
        ""
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9709935011061948]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhyG0u_TcFUh"
      },
      "source": [
        "def train_mlp(input_dim,output_dim,hidden_dim,encoder_weight,pretrained,train_loader_mlp,test_loader_mlp,val_loader_mlp,epochs):\n",
        "  \n",
        "  mlp_net1 = mlp_net(input_dim,output_dim,hidden_dim,encoder_weight,pretrained)\n",
        "  mlp_net1.to(device)\n",
        "  final_test_acc = []\n",
        "  final_val_acc = []\n",
        "  optimizer = torch.optim.Adam(mlp_net1.parameters(), lr=0.01)\n",
        "  loss_fn = torch.nn.CrossEntropyLoss()\n",
        "  val_loss_list = []\n",
        "  train_loss_list = []\n",
        "  val_acc_list = []\n",
        "  test_loss_list = []\n",
        "  test_acc_list = []\n",
        "  '''\n",
        "  train_data_mlp = Dataset(x_train_mlp[0:int(partition_list[0]*size)], y_train_mlp[0:int(partition_list[0]*size)])\n",
        "  train_loader_mlp = torch.utils.data.DataLoader(train_data_mlp, **dataloader_params)\n",
        "  mlp_net2 = mlp_net(input_dim,output_dim,hidden_dim,encoder_weight,pretrained = True)\n",
        "\n",
        "  mlp_net2.to(device)\n",
        "  optimizer = torch.optim.Adam(mlp_net2.parameters(), lr=0.01)\n",
        "  '''\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    val_loss = 0.0\n",
        "    preds = []\n",
        "    acc =0.0\n",
        "    test_acc = 0.0\n",
        "    test_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(train_loader_mlp):\n",
        "                \n",
        "                # Get the inputs: data is a list of [inputs, labels]\n",
        "                x, y = data\n",
        "                #print(x.shape)\n",
        "                # Initialize container for noisy images\n",
        "                #noisy_images = []\n",
        "\n",
        "                # Now get noisy images\n",
        "                \n",
        "                \n",
        "\n",
        "                # Send the inputs and labels to the memory of the device\n",
        "                #noisy_images, flat_clean_imgs = noisy_images.to(device), flat_clean_imgs.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                #x.to(device)\n",
        "                x = x.type(torch.FloatTensor)\n",
        "                y = y.type(torch.LongTensor)\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                pred = mlp_net1.forward(x)\n",
        "                \n",
        "                # Calculate loss\n",
        "                \n",
        "                loss = loss_fn(pred,y)\n",
        "\n",
        "                # Backward\n",
        "                loss.backward()\n",
        "                \n",
        "                # Optimize\n",
        "                optimizer.step()\n",
        "\n",
        "                # Add to running loss\n",
        "                running_loss += loss.item()\n",
        "    running_loss = (running_loss)/len(train_loader_mlp)\n",
        "    print(\"epoch: \",epoch, \"train_loss: \",running_loss)\n",
        "    for j, data in enumerate(val_loader_mlp): \n",
        "      x,y = data \n",
        "      with torch.no_grad():\n",
        "        x = x.type(torch.FloatTensor)\n",
        "        y = y.type(torch.LongTensor)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = mlp_net1.forward(x)\n",
        "        loss = loss_fn(pred,y)\n",
        "        pred = pred.argmax(axis =1)\n",
        "        val_loss += loss.item()\n",
        "        #print(\"pred: \",pred.shape,\"y:\",y.shape)\n",
        "        acc+= np.sum(pred.cpu().numpy()==y.cpu().numpy())/len(pred.cpu().numpy())\n",
        "    val_loss = val_loss/len(val_loader_mlp)\n",
        "    acc = acc/len(val_loader_mlp)\n",
        "    for k, data in enumerate(test_loader_mlp): \n",
        "      x,y = data \n",
        "      with torch.no_grad():\n",
        "        x = x.type(torch.FloatTensor)\n",
        "        y = y.type(torch.LongTensor)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = mlp_net1.forward(x)\n",
        "        loss = loss_fn(pred,y)\n",
        "        pred = pred.argmax(axis =1)\n",
        "        test_loss += loss.item()\n",
        "        #print(\"pred: \",pred[0],\"y:\",y[0])\n",
        "        test_acc+= np.sum(pred.cpu().numpy()==y.cpu().numpy())/len(pred.cpu().numpy())\n",
        "    test_loss = test_loss/len(test_loader_mlp)\n",
        "    test_acc = test_acc/len(test_loader_mlp)\n",
        "    print(\"epoch: \",epoch, \"test_loss: \",test_loss,\"acc: \",acc)\n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(acc)\n",
        "    test_loss_list.append(test_loss)\n",
        "    test_acc_list.append(test_acc)\n",
        "  final_test_acc.append(test_loss_list[-1])\n",
        "  final_val_acc.append(val_loss_list[-1])\n",
        "  clear_gpu(mlp_net1)\n",
        "  return final_val_acc, final_test_acc"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3PvXCFgs6YJ",
        "outputId": "ba24f7eb-4d8a-4115-b647-fc0c1d48d731"
      },
      "source": [
        "len(x_train_mlp)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Np1J5E0k0fd",
        "outputId": "5edb390b-096f-4789-ed1a-f776aed60aa6"
      },
      "source": [
        "loss_fn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcuwowBkthao"
      },
      "source": [
        "Autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "2y4VO1wRyg0n",
        "outputId": "c94a19fc-786e-4214-d298-d877ed16a3a7"
      },
      "source": [
        "#training routine for pretrained mlp\n",
        "\n",
        "epochs = 20\n",
        "partition_list = [0.05,0.1]\n",
        "final_test_acc = []\n",
        "final_val_acc = []\n",
        "\n",
        "val_loss_list = []\n",
        "train_loss_list = []\n",
        "val_acc_list = []\n",
        "test_loss_list = []\n",
        "test_acc_list = []\n",
        "'''\n",
        "train_data_mlp = Dataset(x_train_mlp[0:int(partition_list[0]*size)], y_train_mlp[0:int(partition_list[0]*size)])\n",
        "train_loader_mlp = torch.utils.data.DataLoader(train_data_mlp, **dataloader_params)\n",
        "mlp_net2 = mlp_net(input_dim,output_dim,hidden_dim,encoder_weight,pretrained = True)\n",
        "\n",
        "mlp_net2.to(device)\n",
        "optimizer = torch.optim.Adam(mlp_net2.parameters(), lr=0.01)\n",
        "'''\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  val_loss = 0.0\n",
        "  preds = []\n",
        "  acc =0.0\n",
        "  test_acc = 0.0\n",
        "  test_loss = 0.0\n",
        "  \n",
        "  for i, data in enumerate(train_loader_mlp):\n",
        "              \n",
        "              # Get the inputs: data is a list of [inputs, labels]\n",
        "              x, y = data\n",
        "              #print(x.shape)\n",
        "              # Initialize container for noisy images\n",
        "              #noisy_images = []\n",
        "\n",
        "              # Now get noisy images\n",
        "              \n",
        "              \n",
        "\n",
        "              # Send the inputs and labels to the memory of the device\n",
        "              #noisy_images, flat_clean_imgs = noisy_images.to(device), flat_clean_imgs.to(device)\n",
        "\n",
        "              # Zero the parameter gradients\n",
        "              #x.to(device)\n",
        "              x = x.type(torch.FloatTensor)\n",
        "              y = y.type(torch.LongTensor)\n",
        "              x = x.to(device)\n",
        "              y = y.to(device)\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # Forward\n",
        "              pred = mlp_net2.forward(x)\n",
        "              \n",
        "              # Calculate loss\n",
        "              \n",
        "              loss = loss_fn(pred,y)\n",
        "\n",
        "              # Backward\n",
        "              loss.backward()\n",
        "              \n",
        "              # Optimize\n",
        "              optimizer.step()\n",
        "\n",
        "              # Add to running loss\n",
        "              running_loss += loss.item()\n",
        "  running_loss = (running_loss)/len(train_loader_mlp)\n",
        "  print(\"epoch: \",epoch, \"train_loss: \",running_loss)\n",
        "  for j, data in enumerate(val_loader_mlp): \n",
        "    x,y = data \n",
        "    with torch.no_grad():\n",
        "      x = x.type(torch.FloatTensor)\n",
        "      y = y.type(torch.LongTensor)\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      pred = mlp_net2(x)\n",
        "      loss = loss_fn(pred,y)\n",
        "      pred = pred.argmax(axis =1)\n",
        "      val_loss += loss.item()\n",
        "      #print(\"pred: \",pred,\"y:\",y)\n",
        "      acc+= np.sum(pred.cpu().numpy()==y.cpu().numpy())/len(pred.cpu().numpy())\n",
        "  val_loss = val_loss/len(val_loader_mlp)\n",
        "  acc = acc/len(val_loader_mlp)\n",
        "  for k, data in enumerate(test_loader_mlp): \n",
        "    x,y = data \n",
        "    with torch.no_grad():\n",
        "      x = x.type(torch.FloatTensor)\n",
        "      y = y.type(torch.LongTensor)\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      pred = mlp_net2(x)\n",
        "      loss = loss_fn(pred,y)\n",
        "      pred = pred.argmax(axis =1)\n",
        "      test_loss += loss.item()\n",
        "      #print(\"pred: \",pred,\"y:\",y)\n",
        "      test_acc+= np.sum(pred.cpu().numpy()==y.cpu().numpy())/len(pred.cpu().numpy())\n",
        "  test_loss = test_loss/len(test_loader_mlp)\n",
        "  test_acc = test_acc/len(test_loader_mlp)\n",
        "  print(\"epoch: \",epoch, \"test_loss: \",test_loss,\"acc: \",test_acc)\n",
        "  val_loss_list.append(val_loss)\n",
        "  val_acc_list.append(acc)\n",
        "  test_loss_list.append(test_loss)\n",
        "  test_acc_list.append(test_acc)\n",
        "final_test_acc.append(test_loss[-1])\n",
        "final_val_acc.append(val_loss[-1])\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-261aad070dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m               \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m               \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_net2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m               \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mlp_net2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drrLC7IYb7M9",
        "outputId": "ee6c0134-b55d-40c5-e465-7344135e70c6"
      },
      "source": [
        "test_acc_list"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9425193584070797,\n",
              " 0.9410208102876106,\n",
              " 0.94852046460177,\n",
              " 0.9391731194690266,\n",
              " 0.9445640901548673,\n",
              " 0.9438070381637168,\n",
              " 0.9340949944690266,\n",
              " 0.9499792588495575,\n",
              " 0.9510854535398231,\n",
              " 0.9555119607300885]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTBBkd0I2zjr"
      },
      "source": [
        "def run_experiment_with_x_percent_data(x):\n",
        "  x_train_mlp = X_train1\n",
        "  y_train_mlp = y_train1\n",
        "  x_val_mlp = X_val1\n",
        "  y_val_mlp = y_val1 \n",
        "  temp = list(zip(x_train_mlp, y_train_mlp)) \n",
        "  random.shuffle(temp) \n",
        "  x_train_mlp, y_train_mlp = zip(*temp)\n",
        "  size = len(x_train_mlp)\n",
        "  train_data_mlp = Dataset(x_train_mlp[0:int(*size)], y_train_mlp[0:int(0.05*size)])\n",
        "  train_loader_mlp = torch.utils.data.DataLoader(train_data_mlp, **dataloader_params)\n",
        "  val_data_mlp = Dataset(x_val_mlp, y_val_mlp)\n",
        "  val_loader_mlp = torch.utils.data.DataLoader(val_data_mlp, **dataloader_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3KsnXlmXrdd5",
        "outputId": "d4578b51-9968-42e4-f27b-0746098b16ba"
      },
      "source": [
        "plt.plot(train_loss_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4d23b473c8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAarUlEQVR4nO3dfXRc9X3n8fd3HvQwtp5syzZIsg3GPBgTHiwbSrI8hSRAuzw0PJgmZ0ObltANCd1295RuUsKhJ3taaElOz6G0ZJeG7DY1lJbEoQQSICRNacAymAdjDAZsJGEsYUt+0uPMfPePGZmxkKyRPdLV3Pt5naPMvXeuNN+by/nc69/93jvm7oiISLjEgi5ARERKT+EuIhJCCncRkRBSuIuIhJDCXUQkhBJBffC8efN8yZIlQX28iEhZ2rBhwwfu3jjReoGF+5IlS2hrawvq40VEypKZbS9mPQ3LiIiEkMJdRCSEFO4iIiGkcBcRCSGFu4hICBUV7mZ2iZltMbOtZnbrGO/fYGbdZrYx//O7pS9VRESKNWErpJnFgXuATwEdwHozW+fur41a9UF3v3kKahQRkUkq5sx9NbDV3d929yFgLXDF1JY1vrZtu/mLx19HjyoWERlfMeHeBLQXzHfkl432WTN72cweNrOWsf6Qmd1oZm1m1tbd3X0E5cLLHXu495m36OkbPqLfFxGJglJdUP0RsMTdPwb8FHhgrJXc/T53b3X31sbGCe+eHVNzQzUAHT19R1iqiEj4FRPunUDhmXhzftlB7r7L3Qfzs/8bWFma8j6quSEFQEdP/1R9hIhI2Ssm3NcDy8zsODOrANYA6wpXMLNjCmYvBzaXrsRDNenMXURkQhN2y7h72sxuBp4A4sD97r7JzO4A2tx9HfBVM7scSAO7gRumquC66iS1VQmduYuIHEZRT4V098eAx0Ytu61g+k+APyltaeNrbkgp3EVEDqMs71BtbqjWsIyIyGGUabjnztzV6y4iMrYyDfdq+oYy6nUXERlH2YY7qGNGRGQ8ZRru6nUXETmcsgx39bqLiBxeWYa7et1FRA6vLMMd1OsuInI4ZRzu6nUXERlP2YZ7U0M1nep1FxEZU9mGe3NDigNDGXrV6y4i8hFlHO4jHTMadxcRGS0E4a5xdxGR0co43HUjk4jIeMo23Ouqk9RUJXTmLiIyhrINd1Cvu4jIeMo83KsV7iIiYwhBuPep111EZJQyD3f1uouIjKXMw1297iIiYwlJuKtjRkSkUJmHu3rdRUTGUtbhrl53EZGxlXW4g3rdRUTGEoJwV6+7iMhoZR/uTfXVdPbque4iIoXKPtybG6rZP5hmT7963UVERoQg3NUxIyIyWgjCXb3uIiKjlX24t+jMXUTkI8o+3GurE9RUJhTuIiIFyj7czYym/NMhRUQkp+zDHXQjk4jIaCEJ99yNTOp1FxHJCU24q9ddRORDRYW7mV1iZlvMbKuZ3XqY9T5rZm5mraUrcWLqdRcROdSE4W5mceAe4FJgOXC9mS0fY70a4BbguVIXORH1uouIHKqYM/fVwFZ3f9vdh4C1wBVjrPdnwF8AAyWsryjqdRcROVQx4d4EtBfMd+SXHWRmZwEt7v6vh/tDZnajmbWZWVt3d/ekix2Pet1FRA511BdUzSwG3A380UTruvt97t7q7q2NjY1H+9GFNajXXUSkQDHh3gm0FMw355eNqAFWAM+Y2TbgHGDd9F9U1XPdRURGFBPu64FlZnacmVUAa4B1I2+6+x53n+fuS9x9CfAr4HJ3b5uSisfR3JCiU73uIiJAEeHu7mngZuAJYDPwkLtvMrM7zOzyqS6wWM0N1ewbTLO3Px10KSIigUsUs5K7PwY8NmrZbeOse8HRlzV5I+2Q7T191KXqgihBRGTGCMUdqqAbmURECoUo3HUjk4jIiNCEe111ktnqdRcRAUIU7mamdkgRkbzQhDuM9LprWEZEJGThrl53EREIXbir111EBEIY7pDrdRcRibKQhbt63UVEIHThrl53EREIWbir111EJCdU4a5edxGRnFCFO0BTfTWdvQp3EYm20IW7bmQSEQlluKfYN5BmT/9w0KWIiAQmhOGujhkRkRCGu3rdRURCGO4jZ+4KdxGJrtCFe30qyayKuIZlRCTSQhfuuV73lM7cRSTSQhfugG5kEpHIC3G4a1hGRKIrpOGuXncRibaQhrt63UUk2kIa7up1F5FoC2m4q9ddRKItlOGuXncRibpQhvtIr3unztxFJKJCGe4ATep1F5EIC224q9ddRKIs1OG+V73uIhJRIQ73XDukxt1FJIpCHO66kUlEoivE4a4bmUQkukIb7g2pJKmKuMJdRCKpqHA3s0vMbIuZbTWzW8d4/yYze8XMNprZL81seelLnZxcr7s6ZkQkmiYMdzOLA/cAlwLLgevHCO/vu/tp7n4GcCdwd8krPQL60g4RiapiztxXA1vd/W13HwLWAlcUruDuewtmZwFeuhKPnM7cRSSqEkWs0wS0F8x3AGePXsnMvgz8IVABXFSS6o5SYa97XXUy6HJERKZNyS6ouvs97r4U+GPg62OtY2Y3mlmbmbV1d3eX6qPHpV53EYmqYsK9E2gpmG/OLxvPWuDKsd5w9/vcvdXdWxsbG4uv8gip111EoqqYcF8PLDOz48ysAlgDrCtcwcyWFcz+OvBm6Uo8cup1F5GomnDM3d3TZnYz8AQQB+53901mdgfQ5u7rgJvN7GJgGOgBvjCVRRdLve4iElXFXFDF3R8DHhu17LaC6VtKXFdJjPS6d/ZqWEZEoiW0d6iOaKrXc91FJHpCH+66kUlEoigC4V7Nnv5h9g7oue4iEh0RCHf1uotI9EQg3Ed63RXuIhIdEQp3dcyISHSEPtznzKqgOqledxGJltCH+0iv+/ZdB4IuRURk2oQ+3AFWHTeHX279QB0zIhIZkQj3NataGBjOsm7je0GXIiIyLSIR7qc11XHKMbU8uL594pVFREIgEuFuZqxZ1cIrnXt4tXNP0OWIiEy5SIQ7wJVnNFGRiPFQm87eRST8IhPudakkl61YyCMvdjIwnAm6HBGRKRWZcAe4btUi9g2k+fGrO4IuRURkSkUq3M85fg5L5qZY+7yGZkQk3CIV7mbGtataeO6d3bzdvT/ockREpkykwh3g6rOaiceMh9o6gi5FRGTKRC7c59dWcdHJ83l4QwfDmWzQ5YiITInIhTvk7lj9YP8gT7/eFXQpIiJTIpLhfv6JjSyordQdqyISWpEM90Q8xjUrW3hmSxc79uhRwCISPpEMd4BrW1vIOjysC6siEkKRDfdFc1N8/IS5PNjWTjbrQZcjIlJSkQ13yN2x2tHTz7Nv7Qq6FBGRkop0uH96+QLqU0nWrn836FJEREoq0uFelYxz1ZlN/GTTTnYfGAq6HBGRkol0uAOsWbWIoUyWR17sDLoUEZGSiXy4n7SwhjMX1bP2+Xdx14VVEQmHyIc75O5YfbNrPy+82xt0KSIiJaFwB37jY8cyqyLOg7qwKiIhoXAHZlUm+M+nH8uPXtrBvoHhoMsRETlqCve861a10D+c4dGX9S1NIlL+FO55Z7TUc9KCGtbqYWIiEgIK9zwz47pVLbzU3svmHXuDLkdE5Kgo3AtcdWYTFfGYHgUsImWvqHA3s0vMbIuZbTWzW8d4/w/N7DUze9nMnjKzxaUvdeo1zKrgMysW8siLnQwMZ4IuR0TkiE0Y7mYWB+4BLgWWA9eb2fJRq70ItLr7x4CHgTtLXeh0WbOqhT39wzyx6f2gSxEROWLFnLmvBra6+9vuPgSsBa4oXMHdf+buffnZXwHNpS1z+vza8XNpmVOtoRkRKWvFhHsTUJh0Hfll4/ki8OOx3jCzG82szczauru7i69yGsVixnWtLTz71i627zoQdDkiIkekpBdUzezzQCtw11jvu/t97t7q7q2NjY2l/OiSunplC8m4cecTW4IuRUTkiBQT7p1AS8F8c37ZIczsYuBrwOXuPlia8oKxsK6KWz65jH99eQePvaKbmkSk/BQT7uuBZWZ2nJlVAGuAdYUrmNmZwN+RC/au0pc5/W46fymnNdXxpz94Vc96F5GyM2G4u3sauBl4AtgMPOTum8zsDjO7PL/aXcBs4J/MbKOZrRvnz5WNRDzGXdd8jL0Dw9z2w1eDLkdEZFISxazk7o8Bj41adlvB9MUlrmtGOHlhLV+9aBl/9dM3+PXTdnDpaccEXZKISFF0h+oEbrpgKSuaavnTH2p4RkTKh8J9Asl4jL+85nT29A/zjXWbgi5HRKQoCvcijAzP/Oil93j8VXXPiMjMp3Av0sjwzNfVPSMiZUDhXqRkPMZdV+eGZ27X8IyIzHAK90k45ZhavnLRMta99B6Pv6oHi4nIzKVwn6Tfv2Appx5by9d/8Ao9Gp4RkRlK4T5JI90zvX3qnhGRmUvhfgQ0PCMiM53C/Qj91wuXsvyYXPeMhmdEZKZRuB+hD4dnhrj9RxqeEZGZReF+FJYfmxue+eHG9/S1fCIyoyjcj9LI8MzXHtHwjIjMHAr3ozR6eMbdgy5JREThXgqFwzN/9uhmslkFvIgEq6jnucvEvnLRCfT2D3H/v7/D7gOD3Hn16VQkdOwUkWAo3EskFjNu+43lzJtdyV1PbKGnb5h7P38WqQr9Xywi00+nliVkZnz5whP48988jX97s5vf+s5zusgqIoFQuE+BNasXce/nV/Lajr1c83f/wXu9/UGXJCIRo3CfIp85dSHf+53V7NwzwGfvfZatXfuCLklEIkThPoXOOX4ua790DsMZ5+q//Q9eeLcn6JJEJCIU7lPs1GPr+JffP5e66iSf+85zPLOlK+iSRCQCFO7TYNHcFA/fdC7HzZvF7z7Qxg9e7Ay6JBEJOYX7NGmsqWTtl86hdUkDf/DgRu7/5TtBlyQiIaZwn0a1VUm++9urueTUhdzx6Gvc+fjrelyBiEwJhfs0q0rGuedzZ3H96kX8zTNv8Xvfa+PZrR/okQUiUlK6fTIA8Zjxv65aQcucav72mbd4cnMXi+akuG5VC1evbGZBbVXQJYpImbOghgVaW1u9ra0tkM+eSQaGMzz+6vusXf8uv3p7N/GYceFJ81mzqoULTmokEdc/rkTkQ2a2wd1bJ1pPZ+4Bq0rGufLMJq48s4l3PjjAQ23t/FNbB09u3smC2kquWdnCta0tLJqbCrpUESkjOnOfgYYzWZ5+vYsH17fzzJYusg4fP2Eu161axGdOXUBlIh50iSISkGLP3BXuM9x7vf08vKGDB9e309nbT0MqyZfOX8rvfPw4PVJYJIIU7iGTzTr//tYH3P/Ld/jZlm6OnzeL2y8/lfNObAy6NBGZRsWGu079ykQsZvynZY38/W+v5u9vWEXWnf9y//Pc9H830NHTF3R5IjLDKNzL0IUnz+eJ/3Ye/+MzJ/HMG11cfPfP+eun3mRgOBN0aSIyQyjcy1RlIs6XLzyBp/7oAi46eT53//QNPv2tX/DU5p1BlyYiM0BR4W5ml5jZFjPbama3jvH+eWb2gpmlzezq0pcp42mqr+ZvPreS//fFs0nGjS8+0MYXv7ue7bsOBF2aiARownA3szhwD3ApsBy43syWj1rtXeAG4PulLlCK84ll8/jxLefxtctO4Vdv7+JT3/oFd/9kC/1DGqoRiaJiztxXA1vd/W13HwLWAlcUruDu29z9ZSA7BTVKkSoSMX7vvON5+r9fwGUrFvLXT2/l4rt/zrqX3mPfwHDQ5YnINCrmDtUmoL1gvgM4+0g+zMxuBG4EWLRo0ZH8CSnCgtoqvr3mTK5fvYhvrNvEV//xRcxgaeNsTm+u54yWOk5vqefkhbXqlRcJqWl9/IC73wfcB7k+9+n87Cg6+/i5PPqVT/DsW7t4qb2Xlzp6+fkbXfzzCx0AVMRjLD+2ljNa6jm9pY7Tm+tZMncWsZgFXLmIHK1iwr0TaCmYb84vkzKQiMc478TGgzc7uTvv7RnIhX17Lxvbe3morZ3vPrsNgNqqBKe31NO6eA6fPGU+px5bi5nCXqTcFBPu64FlZnYcuVBfA/zWlFYlU8bMaKqvpqm+mstOOwaATNbZ2rU/F/YdvWx8t5dvP/UG33ryDRbUVnLRyQu4+JT5nLt0HtUVeq6NSDko6vEDZnYZ8G0gDtzv7t80szuANndfZ2argEeABmAAeN/dTz3c39TjB2a2D/YP8syWbp7avJNfvNHNgaEMVckYH186j0+esoCLTp7Pwjo9d15kuunZMlIyg+kMz7+zm6c2d/Hk5p109PQDsKKp9uBZ/Ypj6zRWLzINFO4yJdydN7v28+TmnTy1uYsX3u3BHebXVPJrS+fSuriBlYvncNLCGuIKe5GSU7jLtNiVH755eksXz7+zm+59gwDUVCY4Y1E9Kxc30Lp4Dmcsqmd2pb4bRuRoKdxl2rk7HT39tG3fTdu2HjZs72HLzn24Q8zglGNqc2f2S+bQuriBY+urgy5ZpOwo3GVG2NM/zMb2XjZs203b9h42tvfSl38kwrzZldRWJ6hMxKlKxqgaeU3GqUzkXquScSrz71UmY8yvqWLl4gaWzE2pRVMiSd+hKjNCXXWS809s5Px8n306k+X19/fRtm03r+3Yy4GhDIPDWQbTGQaGM3ywP83AcIbBdJaB4dyygXSWofShT7aYN7vi4JBP65IGTj22TnfbihRQuMu0SsRjrGiqY0VT3aR+L5t1hjJZ3t3dR9u2noNDP09syj3iuDIRy9981cCqJXM4a1EDdankVGyCSFnQsIyUta69A2zY3sP6bT1s2L6bTe/tJZ3N/Td94oLZrFw8h0VzUtRUJaitTlJb+FqVpLY6SWUipiEeKRsalpFImF9bxaWnHcOl+btt+4bS+TH+Htq29/Doy++xbyB92L9REY8dEv6z8l09WXeynrtQnMl+OJ118vOOe269ymSM5voULXOqaW7IvbY0pGhuSOmuXgmEwl1CJVWR4Nyl8zh36TwgF8YDw1n2DQyzd2CYPf3p/HSavf25ZfsOTudeDwymMcs9qiFmEIvFqErah/OHvBqxGBwYzPBm1z5+tqWLwTGuD+QCP0VzQy70W+ZU01hTSUOqgrrqJFVJHQCktBTuEmpmRnVFnOqKOPNrp/5xCdms88H+Qdp7+ujo6ad9dx/tu/vp6O3jpfZefvzKjoPDRoWqk3HqU0nqqpM0pCqoTyWpz782pJLUV+em59dWsbC2inmzK0jEdQFZxqdwFymhWMyYX1vF/NoqVi7+6PvpTJad+wZp393Hrv1D9PQNsad/mJ4DQ/T2D9PbN0Rv3zBvdu0/OD3WwSBmuVbSBbVV+Z9KFo5M1304X1ed1PWEiFK4i0yjRDx28KmcxXB39g+m6e0bpqdviK69g7y/d4CuvQO8v3eAnXsH6ejpY8P23fT0jf1tW/GYETfDLDd9cFjp4HRufuS9mqoEjTWVH/7Mzr3Or6k6uKy2KqGDxgyncBeZwcyMmqokNVVJWuakDrvuwHCG7n2D7CwI/j19Q2TyF4Gz+YvAmezIxeIP571gek//MN37B3m7+wDd+wYZynz02zMrErGDoT9vdiWpijgViVjuJx6jMhmjMh47uKwyET/4XkX+BrVZ+eGyWZUJUhVxZlUkqK6Iq3upRBTuIiFRlYzTMic14UFgMtydvf1puvYN0L1vkO79g7nXfYN05V87evoYGM4wlM4ylMkymM79jL7xrFjxmB0M+1RFnFRlnFRFglkVcVKVCWZX5DqaZlXmDgyzDh4gEsyuTJCqjOdeK+LEY4aR+1cLgOX/Z2SZkTuAjhxKYmYk4vmfWKxkD79zd9LZXNfVcCZ78IA3lRTuIjIuM6MulaQulWTZgppJ/a67M5zJ3Xw2lA/7wXTuIDAwnKVvKE3fcIa+wQwHhtL0DY6ez+Tn0+wfTLPrwBDbd/dxYDD33v6hNFN9m44ZJPMhn4gbyXiMRMxyP/EYiXgu/NOZXHCns1nSmVyQpzPZ3Gs+1At986oVfO7sMS7KlJDCXUSmhJlRkbDcYyEqS//3R9pc9w+mOTCY5sBQmgP5A8PIASCTvxcBwMlNe+6X8dwLIzdyOpB1PgzlTC6shzNOJv+azmbzZ9+58B7OOgYfhn3MiMdyB4GRA0LuYBA7ZJ0zWxpK/3/IKAp3ESlLhW2ujTVTcPQoc2qUFREJIYW7iEgIKdxFREJI4S4iEkIKdxGREFK4i4iEkMJdRCSEFO4iIiEU2NfsmVk3sP0If30e8EEJyyk3Ud7+KG87RHv7te05i929caJfCCzcj4aZtRXzHYJhFeXtj/K2Q7S3X9s+uW3XsIyISAgp3EVEQqhcw/2+oAsIWJS3P8rbDtHefm37JJTlmLuIiBxeuZ65i4jIYSjcRURCqOzC3cwuMbMtZrbVzG4Nup7pZGbbzOwVM9toZm1B1zPVzOx+M+sys1cLls0xs5+a2Zv516n/SpsAjLPtt5tZZ37/bzSzy4KscaqYWYuZ/czMXjOzTWZ2S355VPb9eNs/qf1fVmPuZhYH3gA+BXQA64Hr3f21QAubJma2DWh190jcyGFm5wH7ge+5+4r8sjuB3e7+5/mDe4O7/3GQdU6Fcbb9dmC/u/9lkLVNNTM7BjjG3V8wsxpgA3AlcAPR2Pfjbf+1TGL/l9uZ+2pgq7u/7e5DwFrgioBrkini7r8Ado9afAXwQH76AXL/0YfOONseCe6+w91fyE/vAzYDTURn34+3/ZNSbuHeBLQXzHdwBBtdxhz4iZltMLMbgy4mIAvcfUd++n1gQZDFBOBmM3s5P2wTymGJQma2BDgTeI4I7vtR2w+T2P/lFu5R9wl3Pwu4FPhy/p/ukeW5McXyGVc8evcCS4EzgB3AXwVbztQys9nAPwN/4O57C9+Lwr4fY/sntf/LLdw7gZaC+eb8skhw9878axfwCLlhqqjZmR+THBmb7Aq4nmnj7jvdPePuWeA7hHj/m1mSXLD9g7v/S35xZPb9WNs/2f1fbuG+HlhmZseZWQWwBlgXcE3Twsxm5S+uYGazgE8Drx7+t0JpHfCF/PQXgB8GWMu0Ggm2vKsI6f43MwP+D7DZ3e8ueCsS+3687Z/s/i+rbhmAfPvPt4E4cL+7fzPgkqaFmR1P7mwdIAF8P+zbbmb/CFxA7nGnO4FvAD8AHgIWkXtk9LXuHroLj+Ns+wXk/knuwDbgSwVj0KFhZp8A/g14BcjmF/9PcuPOUdj3423/9Uxi/5dduIuIyMTKbVhGRESKoHAXEQkhhbuISAgp3EVEQkjhLiISQgp3EZEQUriLiITQ/wdYyhckU41YlwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jdbN-S7rtX1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}