{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "3.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7iLHAcAnnvT",
        "outputId": "62c15bbe-0a8f-43da-c2e7-3ba29beabebd"
      },
      "source": [
        "# Import packages\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-12T09:50:46.343383Z",
          "start_time": "2021-01-12T09:50:45.913702Z"
        },
        "id": "wQSOcAMpWIlY"
      },
      "source": [
        "# Import packages\n",
        "%reset -f\n",
        "import pprint\n",
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-12T09:50:46.349210Z",
          "start_time": "2021-01-12T09:50:46.345154Z"
        },
        "code_folding": [
          0
        ],
        "id": "CmxXnIB7WIln"
      },
      "source": [
        "def load_mnist(path, kind='train'):\n",
        "    '''\n",
        "    Load MNIST data from specified path\n",
        "    '''\n",
        "    \n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-12T09:50:46.355884Z",
          "start_time": "2021-01-12T09:50:46.352505Z"
        },
        "code_folding": [
          0
        ],
        "id": "wyzvbcaJWIlo"
      },
      "source": [
        "def _filter(xs, ys, lbls):\n",
        "    '''\n",
        "    Filter observations to construct relevant dataset\n",
        "    '''\n",
        "    idxs = [i for (i, l) in enumerate(ys) if l in lbls]\n",
        "    return xs[idxs, :], ys[idxs]"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-12T09:50:46.359651Z",
          "start_time": "2021-01-12T09:50:46.357209Z"
        },
        "id": "6w-iezqjWIlo"
      },
      "source": [
        "def clear_gpu(model):\n",
        "   '''\n",
        "   Removes model from GPU and clears memory\n",
        "   '''\n",
        "   model = model.to('cpu')\n",
        "   del model\n",
        "   torch.cuda.empty_cache()"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-12T09:50:46.364271Z",
          "start_time": "2021-01-12T09:50:46.360862Z"
        },
        "id": "1NFopA7XWIlp"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    '''\n",
        "    Basic dataset class to work with Torch data loader\n",
        "    '''\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "        # No. of rows in feature array should equal no. of examples\n",
        "        assert len(X) == len(y), print(\"Number of examples don't match up\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-12T09:50:46.370006Z",
          "start_time": "2021-01-12T09:50:46.365304Z"
        },
        "id": "i2nGXFymWIlq"
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "  '''\n",
        "  Basic convolutional neural network class\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    '''\n",
        "    Architecture definition\n",
        "    '''\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(1, 6, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool = torch.nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = torch.nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = torch.nn.Linear(120, 84)\n",
        "    self.fc3 = torch.nn.Linear(84, 5)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    Forward propagation\n",
        "    '''\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x) \n",
        "    \n",
        "    return x"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-12T09:50:49.311570Z",
          "start_time": "2021-01-12T09:50:47.561793Z"
        },
        "id": "ImOz_VZnWIlt"
      },
      "source": [
        "  def get_data(dataloader_params, path='/content/drive/MyDrive/data'): \n",
        "    '''\n",
        "    Prepare data\n",
        "    '''\n",
        "    # Load data\n",
        "    train_images, train_labels = load_mnist(path, 'train')\n",
        "    test_images, test_labels = load_mnist(path, 't10k')\n",
        "    \n",
        "    # Validation images\n",
        "    val_images = train_images[50000:]\n",
        "    val_labels = train_labels[50000:]\n",
        "    \n",
        "    # Train images\n",
        "    train_images = train_images[:50000]\n",
        "    train_labels = train_labels[:50000]\n",
        "    \n",
        "    # Filter the relevant images according to the problem specification\n",
        "    X_train, Y_train = _filter(train_images, train_labels, [0, 1, 4, 5, 8])\n",
        "    X_val, Y_val = _filter(val_images, val_labels, [0, 1, 4, 5, 8])\n",
        "    X_test, Y_test = _filter(test_images, test_labels, [0, 1, 4, 5, 8])\n",
        "\n",
        "    for Y in [Y_train, Y_val, Y_test]:\n",
        "      Y[Y == 4] =  2\n",
        "      Y[Y == 5] =  3\n",
        "      Y[Y == 8] =  4\n",
        "    \n",
        "    # Reshape data into 28 X 28 format\n",
        "    X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 28, 28)\n",
        "    X_val = X_val.reshape(X_val.shape[0], 28, 28)\n",
        "    \n",
        "    # Add new axis to to make sure \n",
        "    X_train = X_train[:, np.newaxis, :, :]\n",
        "    X_test = X_test[:, np.newaxis, :, :]\n",
        "    X_val = X_val[:, np.newaxis, :, :]\n",
        "    \n",
        "    # Dataset\n",
        "    train_data = Dataset(X_train, Y_train)\n",
        "    train_generator = torch.utils.data.DataLoader(train_data, **dataloader_params)\n",
        "    \n",
        "    # Convert into torch tensors and send to device\n",
        "    X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
        "    Y_train = torch.Tensor(Y_train).type(torch.LongTensor)\n",
        "    \n",
        "    # Convert into torch tensors and send to device\n",
        "    X_val = torch.from_numpy(X_val).type(torch.FloatTensor)\n",
        "    Y_val = torch.Tensor(Y_val).type(torch.LongTensor)\n",
        "    \n",
        "    # Convert into torch tensors and send to device\n",
        "    X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
        "    Y_test = torch.Tensor(Y_test).type(torch.LongTensor)\n",
        "    \n",
        "    # Return statement\n",
        "    return(train_generator, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-12T09:57:25.234072Z",
          "start_time": "2021-01-12T09:55:54.243263Z"
        },
        "id": "Z3K3_qaDWIlu"
      },
      "source": [
        "def train(question_no, model_num, epochs=30, batch_size=32, lr=0.1, weight_decay=0, test=False):\n",
        "    '''\n",
        "    Main training loop for convolutional network\n",
        "    '''\n",
        "    # Set the seed so each experiment is reproducible\n",
        "    np.random.seed(21390)\n",
        "    torch.manual_seed(10394)\n",
        "\n",
        "    # Set parameters\n",
        "    dataloader_params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 6}\n",
        "    epochs = epochs\n",
        "  \n",
        "    # Store results here\n",
        "    history = {\n",
        "        'train_accuracy': [],\n",
        "        'train_loss': [], \n",
        "        'val_accuracy': [],\n",
        "        'val_loss': []\n",
        "    }\n",
        "  \n",
        "    # Load data\n",
        "    train_generator, X_train, Y_train, X_val, Y_val, X_test, Y_test = get_data(dataloader_params)\n",
        "  \n",
        "    # Set device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Send all these objects to the relevant device\n",
        "    X_train = X_train.to(device)\n",
        "    Y_train = Y_train.to(device)\n",
        "\n",
        "    # Validation set to GPU\n",
        "    X_val = X_val.to(device)\n",
        "    Y_val = Y_val.to(device)\n",
        "\n",
        "    # Testing set to GPU\n",
        "    X_test = X_test.to(device)\n",
        "    Y_test = Y_test.to(device)\n",
        "\n",
        "    # Create the neural network objects and parameters\n",
        "    net = Net().to(device)\n",
        "  \n",
        "    # Loss function\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr = lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "    if not test:\n",
        "      \n",
        "        # Train for maximum number of epochs given here\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "      \n",
        "            # Initialize running loss value for this epoch\n",
        "            running_loss = 0.0\n",
        "      \n",
        "            # Loop through the generator containing training images\n",
        "            for i, data in enumerate(train_generator):\n",
        "\n",
        "              # Retrieve inputs and labels\n",
        "              inputs, labels = data\n",
        "\n",
        "              # Send them to GPU \n",
        "              inputs = inputs.type(torch.FloatTensor).to(device)\n",
        "              labels =  labels.type(torch.LongTensor).to(device)\n",
        "\n",
        "              # Zero the optimizer gradients\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # Forward propagation\n",
        "              outputs = net.forward(inputs)\n",
        "\n",
        "              # Compute loss\n",
        "              loss = loss_fn(outputs, labels)\n",
        "          \n",
        "              # Backward propogation\n",
        "              loss.backward()\n",
        "\n",
        "              # Weight update\n",
        "              optimizer.step()\n",
        "      \n",
        "            # Compute training loss\n",
        "            with torch.no_grad():\n",
        "          \n",
        "              # Forward propagation\n",
        "              out = net.forward(X_train)\n",
        "\n",
        "              # Prediction \n",
        "              preds = out.argmax(axis=1)\n",
        "\n",
        "              # Get accuracy \n",
        "              accuracy = sum(preds == Y_train)/len(Y_train)\n",
        "          \n",
        "              # Get loss \n",
        "              loss = loss_fn(out, Y_train)\n",
        "\n",
        "              print(\"Train accuracy {}, Train Loss: {}\".format(accuracy, loss))\n",
        "\n",
        "              # Append to history record\n",
        "              history['train_accuracy'].append(accuracy)\n",
        "              history['train_loss'].append(loss)\n",
        "\n",
        "          \n",
        "            # Compute validation loss\n",
        "            with torch.no_grad():\n",
        "        \n",
        "              # Forward propogation\n",
        "              out = net.forward(X_val)\n",
        "\n",
        "              # Prediction \n",
        "              preds = out.argmax(axis=1)\n",
        "        \n",
        "              # Calculate accuracy\n",
        "              accuracy = sum(preds == Y_val)/len(Y_val)\n",
        "\n",
        "              # Calculate loss \n",
        "              loss = loss_fn(out, Y_val)\n",
        "\n",
        "              # Print statement\n",
        "              print(\"Val. accuracy {}, Val. Loss:, {}\".format(accuracy, loss))\n",
        "        \n",
        "              # Append to history record\n",
        "              history['val_accuracy'].append(accuracy)\n",
        "              history['val_loss'].append(loss)\n",
        "\n",
        "            if epoch %5 == 0:\n",
        "          \n",
        "              model_state = {\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': net.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'history': history\n",
        "                    }\n",
        "          \n",
        "              save_checkpoint(model_state, question_no, model_num)\n",
        "    \n",
        "\n",
        "        # Plot and save epoch by epoch results\n",
        "        plot_results(history, 'loss', model_num=model_num)\n",
        "        plot_results(history, 'accuracy', model_num=model_num)\n",
        "\n",
        "        # Return statement\n",
        "        return(history)\n",
        "        \n",
        "    # If the test flag is True we execute this\n",
        "    if test:\n",
        "\n",
        "        # First use helper function given below to load checkpoints file\n",
        "        checkpoint = load_checkpoint(question_no = question_no, model_num=model_num)\n",
        "\n",
        "        # Load model state dictionary\n",
        "        net.load_state_dict(checkpoint['model_state_dict'])\n",
        "        \n",
        "        # Load optimizer state dictionary\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        \n",
        "        # Set model to evaluation mode to make sure any batch norm and dropout layers are set correctly\n",
        "        net.eval()\n",
        "\n",
        "        # Now do the testing process\n",
        "        with torch.no_grad():\n",
        "        \n",
        "            # Forward propogation\n",
        "            out = net.forward(X_test)\n",
        "        \n",
        "            # Prediction \n",
        "            preds = out.argmax(axis=1)\n",
        "        \n",
        "            # Calculate accuracy\n",
        "            accuracy = sum(preds == Y_test)/len(Y_test)\n",
        "        \n",
        "            # Calculate loss \n",
        "            loss = loss_fn(out, Y_test)\n",
        "\n",
        "            # Print success message\n",
        "            print(\"Testing completed! Saving results now...\")\n",
        "\n",
        "            # Print accuracy \n",
        "            print(accuracy)\n",
        "\n",
        "            # Print losss\n",
        "            print(loss)\n",
        "        \n",
        "            # Append to history record\n",
        "            checkpoint['test_accuracy'] = accuracy\n",
        "        \n",
        "            # Append loss to history record\n",
        "            checkpoint['test_loss'] = loss\n",
        "\n",
        "        # Return statement    \n",
        "        return(preds, Y_test)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WufZvTd4r86"
      },
      "source": [
        "def plot_results(history, lab, model_num, path='/content/drive/MyDrive/'):\n",
        "    '''\n",
        "    Convenience function to plot results\n",
        "    '''\n",
        "    # Construct model name\n",
        "    model_name = str(model_num) + '_' + lab + '.png'\n",
        "    path = os.path.join(path, '1_figs', model_name)\n",
        "    \n",
        "    # Plot the results\n",
        "    plt.plot(history['train_' + lab], label='Train')\n",
        "    plt.plot(history['val_' + lab], label='Validation')\n",
        "  \n",
        "    # Add annotations\n",
        "    plt.legend()\n",
        "    plt.title(lab.title() + ' by Epoch')\n",
        "  \n",
        "    # Save the figure and close the plot\n",
        "    plt.savefig(path)\n",
        "    plt.show()\n",
        "    plt.clf()"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJm6U0GS8t0s"
      },
      "source": [
        "def get_results(question_no, model_num):\n",
        "  '''\n",
        "  Take in a results dictionary \n",
        "  and return epoch on which \n",
        "  minimum validation loss was\n",
        "  reached, minimum val. loss on\n",
        "  that epoch, and min. accuracy\n",
        "  on that epoch\n",
        "  '''\n",
        "  # Load the trained weights\n",
        "  checkpoint = load_checkpoint(question_no = question_no, model_num=model_num)\n",
        "\n",
        "  # Load the history object which contains a record of losses\n",
        "  history = checkpoint['history'] \n",
        "\n",
        "  # Find the epoch on which the minimum validation loss was reached\n",
        "  best_val_epoch = np.argmin(np.array(history['val_loss']))\n",
        "  \n",
        "  # Store validation metrics\n",
        "  best_epoch_val_loss = np.array(history['val_loss'][best_val_epoch])\n",
        "  best_epoch_val_accuracy = np.array(history['val_accuracy'][best_val_epoch])\n",
        "\n",
        "  # Store training metrics\n",
        "  best_epoch_train_loss = np.array(history['train_loss'][best_val_epoch])\n",
        "  best_epoch_train_accuracy = np.array(history['train_accuracy'][best_val_epoch])\n",
        "  \n",
        "  # Store best results in a list\n",
        "  results = {'best_val_epoch': best_val_epoch, \n",
        "             'best_epoch_val_loss': best_epoch_val_loss, \n",
        "             'best_epoch_val_accuracy': best_epoch_val_accuracy, \n",
        "             'best_epoch_train_loss': best_epoch_train_loss,\n",
        "             'best_epoch_train_accuracy': best_epoch_train_accuracy, \n",
        "             'final_train_loss': history['train_loss'][-1],\n",
        "             'final_train_accuracy': history['train_accuracy'][-1],\n",
        "             'final_val_loss': history['val_loss'][-1], \n",
        "             'final_val_accuracy': history['val_accuracy'][-1]}\n",
        "\n",
        "  # Return statement\n",
        "  return(results)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E2aWCKewn6V"
      },
      "source": [
        "def save_checkpoint(model_state, question_no, model_num):\n",
        "    '''\n",
        "    Save model state using this function\n",
        "    '''\n",
        "    checkpoints_path = '/content/drive/MyDrive/1_checkpoints/{}_{}.pt'.format(question_no, model_num)\n",
        "    \n",
        "    torch.save(model_state, checkpoints_path)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjBI_pNaxFyG"
      },
      "source": [
        "def load_checkpoint(question_no, model_num):\n",
        "    '''\n",
        "    Save model state using this function\n",
        "    '''\n",
        "    # Create checkpoints path\n",
        "    checkpoints_path = '/content/drive/MyDrive/1_checkpoints/{}_{}.pt'.format(question_no, model_num)\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoints_path)\n",
        "    \n",
        "    # Return statement\n",
        "    return(checkpoint)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd85GRPu871A"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "def get_confusion_matrix(pred_list, lbl_list, question_no, model_num, dest_path='/content/drive/MyDrive/1_results'):\n",
        "    '''\n",
        "    Evaluate model on the test set\n",
        "    '''\n",
        "    cols = ['T-shirt/top', 'Trouser', 'Coat', 'Sandal', 'Bag']\n",
        "    rows = ['T-shirt/top', 'Trouser', 'Coat', 'Sandal', 'Bag']\n",
        "\n",
        "    conf_mat=confusion_matrix(lbl_list.numpy(), pred_list.numpy())\n",
        "    cf = pd.DataFrame(conf_mat)\n",
        "    cf.columns = cols \n",
        "    cf.index = rows\n",
        "\n",
        "    cf.to_csv(os.path.join(dest_path, 'confusion_matrix_{}_{}.csv'.format(question_no, model_num)))\n",
        "    print(cf)\n",
        "      \n",
        "    # Print per class accuracy\n",
        "    class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
        "    ca = pd.DataFrame(class_accuracy).T\n",
        "\n",
        "    ca.columns = cols\n",
        "    ca.index = ['Accuracy']\n",
        "    \n",
        "    ca.to_csv(os.path.join(dest_path, 'class_accuracies_{}_{}.csv'.format(question_no, model_num)))\n",
        "    print(ca)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtvPRwglvTKx"
      },
      "source": [
        "def execute_train_pipeline(question_no, model_num, test):\n",
        "    '''\n",
        "    Execute training for different model objects\n",
        "    '''\n",
        "    if model_num == 10:\n",
        "      results = train(question_no, model_num, lr=0.00001, batch_size=32, epochs=70, weight_decay=0.01, test=test)\n",
        "\n",
        "    if test:\n",
        "      \n",
        "      # First make the confusion matrix\n",
        "      get_confusion_matrix(*results, question_no, model_num)\n",
        "      \n",
        "      # Next store the\n",
        "      final_results = get_results(question_no, model_num)\n",
        "\n",
        "      pp = pprint.PrettyPrinter(indent=4)\n",
        "      pp.pprint(final_results)\n",
        "      "
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_puT_fZ-7Cb"
      },
      "source": [
        "train_results = execute_train_pipeline(question_no=1, model_num=10, test=False)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV-ktPWTngQL",
        "outputId": "59c556f9-9449-4c7c-dd24-020929b7fabc"
      },
      "source": [
        "test_results = execute_train_pipeline(question_no=1, model_num=10, test=True)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing completed! Saving results now...\n",
            "tensor(0.9856)\n",
            "tensor(0.0470)\n",
            "             T-shirt/top  Trouser  Coat  Sandal  Bag\n",
            "T-shirt/top          971        2    14       3   10\n",
            "Trouser                3      987     8       0    2\n",
            "Coat                   6        2   990       1    1\n",
            "Sandal                 0        1     0     998    1\n",
            "Bag                    9        1     5       3  982\n",
            "          T-shirt/top  Trouser  Coat  Sandal   Bag\n",
            "Accuracy         97.1     98.7  99.0    99.8  98.2\n",
            "{   'best_epoch_train_accuracy': array(0.99503505, dtype=float32),\n",
            "    'best_epoch_train_loss': array(0.02126815, dtype=float32),\n",
            "    'best_epoch_val_accuracy': array(0.98567164, dtype=float32),\n",
            "    'best_epoch_val_loss': array(0.05003582, dtype=float32),\n",
            "    'best_val_epoch': 56,\n",
            "    'final_train_accuracy': tensor(0.9954),\n",
            "    'final_train_loss': tensor(0.0193),\n",
            "    'final_val_accuracy': tensor(0.9863),\n",
            "    'final_val_loss': tensor(0.0506)}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}